{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca480e8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T18:32:50.603905Z",
     "iopub.status.busy": "2025-05-20T18:32:50.603555Z",
     "iopub.status.idle": "2025-05-20T20:30:40.165845Z",
     "shell.execute_reply": "2025-05-20T20:30:40.165013Z"
    },
    "papermill": {
     "duration": 7069.56754,
     "end_time": "2025-05-20T20:30:40.167159",
     "exception": false,
     "start_time": "2025-05-20T18:32:50.599619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 18:32:54.321528: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747765974.577895      20 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747765974.648934      20 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "I0000 00:00:1747765991.731594      20 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1747765991.732424      20 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|          | 0/21367 [00:00<?, ?it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1747765997.191599      62 service.cc:148] XLA service 0x7a3ef0003460 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1747765997.192945      62 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1747765997.192970      62 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1747765997.687721      62 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1747766000.683111      62 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "Extracting features: 100%|██████████| 21367/21367 [37:21<00:00,  9.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 18ms/step - loss: 6.8640\n",
      "Epoch 2/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 5.7969\n",
      "Epoch 3/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - loss: 5.5133\n",
      "Epoch 4/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - loss: 5.3518\n",
      "Epoch 5/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - loss: 5.2221\n",
      "Epoch 6/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - loss: 5.1298\n",
      "Epoch 7/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - loss: 5.0887\n",
      "Epoch 8/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 5.0097\n",
      "Epoch 9/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 17ms/step - loss: 4.9885\n",
      "Epoch 10/10\n",
      "\u001b[1m667/667\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 17ms/step - loss: 4.8571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 3771/3771 [06:26<00:00,  9.75it/s]\n",
      "Generating captions: 100%|██████████| 3771/3771 [1:11:17<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Submission saved to submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from pickle import dump, load\n",
    "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, Add\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import tensorflow as tf\n",
    "\n",
    "# ------------------------- Text Preprocessing -------------------------\n",
    "\n",
    "def load_captions_from_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    descriptions = {}\n",
    "    for _, row in df.iterrows():\n",
    "        img_id = str(row[\"image_id\"]).split('.')[0]\n",
    "        cap = row[\"caption\"]\n",
    "        descriptions.setdefault(img_id, []).append(cap)\n",
    "    return descriptions\n",
    "\n",
    "def clean_captions(captions):\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for img_id, caps in captions.items():\n",
    "        for i in range(len(caps)):\n",
    "            text = caps[i].replace(\"-\", \" \").lower()\n",
    "            words = text.split()\n",
    "            words = [w.translate(table) for w in words if w.isalpha() and len(w) > 1]\n",
    "            caps[i] = 'startseq ' + ' '.join(words) + ' endseq'\n",
    "    return captions\n",
    "\n",
    "def save_descriptions(captions, filename=\"descriptions.txt\"):\n",
    "    lines = []\n",
    "    for img_id, desc_list in captions.items():\n",
    "        for desc in desc_list:\n",
    "            lines.append(f\"{img_id}\\t{desc}\")\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "# ------------------------- Feature Extraction -------------------------\n",
    "\n",
    "def extract_features(directory, image_names=None):\n",
    "    model = Xception(include_top=False, pooling='avg')\n",
    "    features = {}\n",
    "    image_list = os.listdir(directory)\n",
    "    if image_names:\n",
    "        image_list = [img for img in image_list if img.split('.')[0] in image_names]\n",
    "    for img_name in tqdm(image_list, desc=\"Extracting features\"):\n",
    "        img_path = os.path.join(directory, img_name)\n",
    "        image = load_img(img_path, target_size=(299, 299))\n",
    "        image = img_to_array(image)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = preprocess_input(image)\n",
    "        feature = model.predict(image, verbose=0)\n",
    "        features[img_name.split('.')[0]] = feature\n",
    "    return features\n",
    "\n",
    "# ------------------------- Tokenizer and Sequences -------------------------\n",
    "\n",
    "def create_tokenizer(descriptions):\n",
    "    all_desc = [d for descs in descriptions.values() for d in descs]\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(all_desc)\n",
    "    return tokenizer\n",
    "\n",
    "def max_caption_length(descriptions):\n",
    "    all_desc = [d for descs in descriptions.values() for d in descs]\n",
    "    return max(len(d.split()) for d in all_desc)\n",
    "\n",
    "def create_sequences(tokenizer, max_len, desc_list, feature):\n",
    "    x_img, x_seq, y = [], [], []\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    for desc in desc_list:\n",
    "        seq = tokenizer.texts_to_sequences([desc])[0]\n",
    "        for i in range(1, len(seq)):\n",
    "            in_seq, out_seq = seq[:i], seq[i]\n",
    "            in_seq = pad_sequences([in_seq], maxlen=max_len, padding='post')[0]  \n",
    "            out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "            x_img.append(feature)\n",
    "            x_seq.append(in_seq)\n",
    "            y.append(out_seq)\n",
    "    return np.array(x_img), np.array(x_seq), np.array(y)\n",
    "\n",
    "def data_generator(descriptions, features, tokenizer, max_len):\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    def gen():\n",
    "        for img_id, desc_list in descriptions.items():\n",
    "            feature = features[img_id][0]\n",
    "            x_img, x_seq, y = create_sequences(tokenizer, max_len, desc_list, feature)\n",
    "            for i in range(len(x_img)):\n",
    "                yield (x_img[i], x_seq[i]), y[i]\n",
    "    output_signature = (\n",
    "        (tf.TensorSpec([2048], tf.float32), tf.TensorSpec([max_len], tf.int32)),\n",
    "        tf.TensorSpec([vocab_size], tf.float32)\n",
    "    )\n",
    "    return tf.data.Dataset.from_generator(gen, output_signature=output_signature)\n",
    "\n",
    "# ------------------------- Model Definition -------------------------\n",
    "\n",
    "def define_model(vocab_size, max_len):\n",
    "    inputs1 = Input(shape=(2048,))\n",
    "    fe1 = Dropout(0.5)(inputs1)\n",
    "    fe2 = Dense(256, activation='relu')(fe1)\n",
    "\n",
    "    inputs2 = Input(shape=(max_len,))\n",
    "    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "    se2 = Dropout(0.5)(se1)\n",
    "    se3 = LSTM(256, unroll=True)(se2)\n",
    "\n",
    "    decoder1 = Add()([fe2, se3])\n",
    "    decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "    outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "# ------------------------- Training -------------------------\n",
    "\n",
    "def train_model(descriptions, features, tokenizer, max_len, epochs=10):\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    model = define_model(vocab_size, max_len)\n",
    "    \n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"models/cp.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor='loss',\n",
    "        mode='min',\n",
    "        save_weights_only=False\n",
    "    )\n",
    "    \n",
    "    dataset = data_generator(descriptions, features, tokenizer, max_len).batch(32).repeat()\n",
    "    steps = sum(len(v) for v in descriptions.values()) // 32\n",
    "    \n",
    "    model.fit(dataset, epochs=epochs, steps_per_epoch=steps, callbacks=[cp_callback])\n",
    "    model.save(\"models/model_final.keras\") \n",
    "    return model\n",
    "\n",
    "# ------------------------- Caption Generation -------------------------\n",
    "\n",
    "def generate_caption(model, tokenizer, photo, max_len):\n",
    "    in_text = 'startseq'\n",
    "    for _ in range(max_len):\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_len)\n",
    "        yhat = model.predict([photo, sequence], verbose=0)\n",
    "        yhat = np.argmax(yhat)\n",
    "        word = next((w for w, i in tokenizer.word_index.items() if i == yhat), None)\n",
    "        if not word:\n",
    "            break\n",
    "        in_text += ' ' + word\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "    return in_text.replace('startseq', '').replace('endseq', '').strip()\n",
    "\n",
    "# ------------------------- Submission Creation -------------------------\n",
    "\n",
    "def create_submission(test_img_dir, model_path, tokenizer, max_len, test_csv_path, output_csv='submission.csv'):\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    test_df = pd.read_csv(test_csv_path, dtype={'image_id': str})\n",
    "    image_ids = [img_id.replace('.jpg', '') for img_id in test_df['image_id']]\n",
    "    \n",
    "    features = extract_features(test_img_dir, image_names=image_ids)\n",
    "    \n",
    "    captions = []\n",
    "    for img_id in tqdm(image_ids, desc=\"Generating captions\"):\n",
    "        feature = features.get(img_id, np.zeros((1, 2048)))\n",
    "        caption = generate_caption(model, tokenizer, feature, max_len)\n",
    "        captions.append(caption)\n",
    "    \n",
    "    pd.DataFrame({'image_id': test_df['image_id'], 'caption': captions}).to_csv(output_csv, index=False)\n",
    "    print(f\"✅ Submission saved to {output_csv}\")\n",
    "\n",
    "# ------------------------- Main (Kaggle notebook uyumlu) -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    base_dir = \"/kaggle/input/obss-intern-competition-2025\"\n",
    "    train_csv = os.path.join(base_dir, \"train.csv\")\n",
    "    test_csv = os.path.join(base_dir, \"test.csv\")\n",
    "    train_dir = os.path.join(base_dir, \"train/train\")\n",
    "    test_dir = os.path.join(base_dir, \"test/test\")\n",
    "\n",
    "    all_desc = load_captions_from_csv(train_csv)\n",
    "    cleaned_desc = clean_captions(all_desc)\n",
    "    save_descriptions(cleaned_desc)\n",
    "\n",
    "    features = extract_features(train_dir, image_names=cleaned_desc.keys())\n",
    "    dump(features, open(\"features.p\", \"wb\"))\n",
    "\n",
    "    tokenizer = create_tokenizer(cleaned_desc)\n",
    "    max_len = max_caption_length(cleaned_desc)\n",
    "\n",
    "    features = load(open(\"features.p\", \"rb\"))\n",
    "    train_features = {k: features[k] for k in cleaned_desc}\n",
    "\n",
    "    model = train_model(cleaned_desc, train_features, tokenizer, max_len)\n",
    "\n",
    "    create_submission(\n",
    "        test_img_dir=test_dir,\n",
    "        model_path=\"models/cp.keras\",\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len,\n",
    "        test_csv_path=test_csv\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e3c769",
   "metadata": {
    "papermill": {
     "duration": 1.113224,
     "end_time": "2025-05-20T20:30:42.420790",
     "exception": false,
     "start_time": "2025-05-20T20:30:41.307566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bd78f3",
   "metadata": {
    "papermill": {
     "duration": 1.039957,
     "end_time": "2025-05-20T20:30:44.576393",
     "exception": false,
     "start_time": "2025-05-20T20:30:43.536436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 12268213,
     "sourceId": 101408,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7083.561141,
   "end_time": "2025-05-20T20:30:49.284257",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-20T18:32:45.723116",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
